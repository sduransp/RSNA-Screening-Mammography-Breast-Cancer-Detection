{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing libraries\nimport numpy as np \nimport pandas as pd \nimport shutil\nimport os\nimport cv2\nimport glob\nfrom PIL import Image\n!pip install \"/kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\"\nimport dicomsdl\nimport pydicom as dicom\nimport matplotlib.pyplot as plt\nimport random\nimport csv\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial exploration\n\nFirst, I am going to import the datasets and perform an initial exploration on them. The competition requires to classify images in a binary mode, using F1 score as evaluation criteria. Therefore, it is very important to have a balanced model, not biased towards any class.","metadata":{}},{"cell_type":"code","source":"# reading the csv file\ntrain_df = pd.read_csv(r\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")\ntest_df = pd.read_csv(r\"/kaggle/input/rsna-breast-cancer-detection/test.csv\")\n# initial exploration\nprint(train_df.head())\n#print(test_df.head())\n# number of different patients\nprint(\"The number of unique patients on training set: \"+str(len(train_df.patient_id.unique())))\nprint(\"The number of unique patients on testing set: \"+str(len(test_df.patient_id.unique())))\n# number of positive and negative classes\nprint(\"The distribution of training classes\")\nprint(train_df[\"cancer\"].value_counts())\n# number of positive and negative classes grouped by machine ID\nprint(\"The distribution of training classes by machine ID\")\n# selecting rows based on having cancer\ncancer_df = train_df[train_df['cancer'] == 1]\nnocancer_df = train_df[train_df['cancer'] == 0]\nprint(\"cancer cases\")\nprint(cancer_df.groupby([\"machine_id\"])[\"machine_id\"].count())\nprint(\"no cancer cases\")\nprint(nocancer_df.groupby([\"machine_id\"])[\"machine_id\"].count())\nprint(\"cancer cases\")\nprint(cancer_df.groupby([\"biopsy\"])[\"biopsy\"].count())\nprint(\"no cancer cases\")\nprint(nocancer_df.groupby([\"biopsy\"])[\"biopsy\"].count())\nprint(\"cancer cases\")\nprint(cancer_df.groupby([\"invasive\"])[\"invasive\"].count())\nprint(\"no cancer cases\")\nprint(nocancer_df.groupby([\"invasive\"])[\"invasive\"].count())\nprint(\"cancer cases\")\nprint(cancer_df.groupby([\"implant\"])[\"implant\"].count())\nprint(\"no cancer cases\")\nprint(nocancer_df.groupby([\"implant\"])[\"implant\"].count())\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:22:36.374001Z","iopub.execute_input":"2023-01-03T22:22:36.374565Z","iopub.status.idle":"2023-01-03T22:22:36.514537Z","shell.execute_reply.started":"2023-01-03T22:22:36.374535Z","shell.execute_reply":"2023-01-03T22:22:36.513141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The vast majority of images do not contain cancer, as I was expecting. This is a severely imbalanced dataset, which can cause the model to gravitate towards the non cancer class. For this, I am going to use an undersampling strategy at the beginning, just for creating the early version of the model.\n\nImportantly, images with and without cancer have been taken by the same machines on a similar proportion, which should not create any spurious correlation based on machine id. \n\nI am a bit concerned about leaky validation, since same patients have several images. Some of these images may end up in training and validation, increasing the likelihood of a leaky validation. I will try to contain only 1 image per patient for the non_cancer class. In addition, I will name the images using a criteria patient_id+img_name+file_extension, so I can split then just by ordering them by name.\n\nImportantly, 100% of cancer images do have biopsy, whereas a small percentage of non_cancer images have biopsy. We need to make sure that we have enough biopsy non cancer images in the training set. I will go for 50% biopsy, 50% non_biopsy.\n\nSimilarly, we need to include around 10-20 implant images in the non cancer bucket, so we make sure implant images are included. \n","metadata":{}},{"cell_type":"code","source":"# creating directories for classes\nos.makedirs(r\"/kaggle/working/0\",exist_ok=True)\nos.makedirs(r\"/kaggle/working/1\",exist_ok=True)\n# saving out directories as variables\nout_cancer = r\"/kaggle/working/1\"\nout_nocancer = r\"/kaggle/working/0\"\ninput_path = r\"/kaggle/input/rsna-breast-cancer-detection/train_images\"\n# creating a small training set for initial experimentation\npatient_used = []\nnumber_no_cancer = 0\nnumber_no_cancer_bio = 0\nnumber_no_cancer_no_bio = 0\n# shuffling dataframe\ntrain_df_sh = train_df.sample(frac=1).reset_index(drop=True)\n# creating the dataframe\nfor index, row in train_df_sh.iterrows():\n    # if the image corresponds to a patient with cancer\n    if row[\"cancer\"] == 1:\n        # defining the patient id as variable\n        patient_id = str(row[\"patient_id\"])\n        # defining the image name as variable\n        img_name = str(row[\"image_id\"])+\".dcm\"\n        # output image name - combination of patiend id + image\n        out_name = patient_id+\"_\"+img_name\n        # copy this image\n        shutil.copy(os.path.join(input_path,patient_id,img_name),os.path.join(out_cancer,out_name))\n    else:    \n        # obtaining the patient id  \n        patient_id = str(row[\"patient_id\"])\n        # if we have already extracted one image from this patient\n        if patient_id in patient_used:\n            # skip it\n            continue\n        else:\n            # appending the patient so we do not use it in the future\n            patient_used.append(patient_id)\n            # if we have copied as many non-cancer images as cancer images, break\n            if number_no_cancer >= 1158:\n                continue\n            # grabbing the biopsy variable\n            biopsy = str(row[\"biopsy\"])\n            # if this image corresponds to a biopsy case\n            if biopsy == \"1\":\n                # we increase the biopsy images counter \n                number_no_cancer_bio = number_no_cancer_bio + 1\n                # if the number of biopsy images greater than 50%, we skip it\n                if number_no_cancer_bio > int(1158/2)+1:\n                    continue\n                else:\n                    # else, we include this image in the collection\n                    # defining the img name\n                    img_name = str(row[\"image_id\"])+\".dcm\"\n                    out_name = patient_id+\"_\"+img_name\n                    # copying the image\n                    shutil.copy(os.path.join(input_path,patient_id,img_name),os.path.join(out_nocancer,out_name))\n                    # adding +1 in the non cancer images collected\n                    number_no_cancer += 1\n            # if the image do not contain biopsy, same\n            else:\n                # increasing the counter\n                number_no_cancer_no_bio = number_no_cancer_no_bio + 1\n                # if we have already grabbed more than 50% of the dataset, skip it\n                if number_no_cancer_no_bio > int(1158/2)+1:\n                    continue\n                else:\n                    # else, we include this image in the collection\n                    # defining the image name\n                    img_name = str(row[\"image_id\"])+\".dcm\"\n                    out_name = patient_id+\"_\"+img_name\n                    # copying\n                    shutil.copy(os.path.join(input_path,patient_id,img_name),os.path.join(out_nocancer,out_name))\n                    # adding +1 in the non cancer images collected\n                    number_no_cancer += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:22:36.515958Z","iopub.execute_input":"2023-01-03T22:22:36.516384Z","iopub.status.idle":"2023-01-03T22:25:07.262817Z","shell.execute_reply.started":"2023-01-03T22:22:36.516322Z","shell.execute_reply":"2023-01-03T22:25:07.260991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look on how many images we have collected for each class following the previous criteria","metadata":{}},{"cell_type":"code","source":"print(\"Number of no cancer images: \"+str(len(os.listdir(r\"/kaggle/working/0\"))))\nprint(\"Number of cancer images: \"+str(len(os.listdir(r\"/kaggle/working/1\"))))","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:07.265297Z","iopub.execute_input":"2023-01-03T22:25:07.266027Z","iopub.status.idle":"2023-01-03T22:25:07.274623Z","shell.execute_reply.started":"2023-01-03T22:25:07.265981Z","shell.execute_reply":"2023-01-03T22:25:07.273843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is somewhat imbalanced towards cancer images. However, this is something we can fix using clas weights on the loss function. For this early version of the model, I will proceed with this dataset.","metadata":{}},{"cell_type":"markdown","source":"## Training and validation set\n\nFor creating these, I will follow the typical Keras folder schema:\n\n- training\n    - class A\n        - img1\n        - img2\n        - ...\n    - class B\n        - img 1\n        - img 2\n        - ...\n- val\n    - class A\n        - img 1\n        - img 2\n        - ...\n    - class B\n        - img 1\n        - img 2\n        - ...\n\nAs there are not too many images (2.1k in total), I am going to split the sets 80-20 for training and validation.\n\nGiven the small amount of data I have for training and validation, I should be using a k-fold validation strategy. However, as I want to train the first version of the model, I will proceed with a hold-out validation strategy.","metadata":{}},{"cell_type":"code","source":"print(\"Creating the training and validation directories\")\n\"\"\"\nSplitting in training and validation set - this will happen sequentially, so \nno same patient ends up in train and val, which could provoke a leaky validation\n\"\"\"\n# creating directories\nos.makedirs(os.path.join(\"/kaggle/working/training\",\"0\"))\nos.makedirs(os.path.join(\"/kaggle/working/training\",\"1\"))\nos.makedirs(os.path.join(\"/kaggle/working/val\",\"0\"))\nos.makedirs(os.path.join(\"/kaggle/working/val\",\"1\"))\n\n# defining number of images variables\nnumber_cancer = len(os.listdir(r\"/kaggle/working/1\"))\nnumber_no_cancer = len(os.listdir(r\"/kaggle/working/0\"))\n\n# reorganising training and validation set\nfor ix,item in enumerate(os.listdir(r\"/kaggle/working/1\")):\n    if ix > int(number_cancer*0.8):\n        shutil.move(os.path.join(r\"/kaggle/working/1\",item),os.path.join(r\"/kaggle/working/val\",\"1\",item))\n    else:\n        shutil.move(os.path.join(r\"/kaggle/working/1\",item),os.path.join(\"/kaggle/working/training\",\"1\",item))\n\nfor ix,item in enumerate(os.listdir(r\"/kaggle/working/0\")):\n    if ix > int(number_no_cancer*0.8):\n        shutil.move(os.path.join(r\"/kaggle/working/0\",item),os.path.join(r\"/kaggle/working/val\",\"0\",item))\n    else:\n        shutil.move(os.path.join(r\"/kaggle/working/0\",item),os.path.join(r\"/kaggle/working/training\",\"0\",item))\n\nprint(\"The training and val directories have been created\")","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:07.277435Z","iopub.execute_input":"2023-01-03T22:25:07.277965Z","iopub.status.idle":"2023-01-03T22:25:08.443671Z","shell.execute_reply.started":"2023-01-03T22:25:07.277937Z","shell.execute_reply":"2023-01-03T22:25:08.441371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Removing original images directories\")\n# removing the legacy folders\nshutil.rmtree(r\"/kaggle/working/1\")\nshutil.rmtree(r\"/kaggle/working/0\")","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:08.446548Z","iopub.execute_input":"2023-01-03T22:25:08.447180Z","iopub.status.idle":"2023-01-03T22:25:09.991712Z","shell.execute_reply.started":"2023-01-03T22:25:08.447125Z","shell.execute_reply":"2023-01-03T22:25:09.989686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pre-processing images\n\nThe images are in .dcm format, hence I will be transforming them into .png which a more commonly used format for images. Alternatively, I could be transforming them into .jpg, but this format applies a compression that I prefer avoiding.\n\nFirst, I am going to do an visual analyses of those images.","metadata":{}},{"cell_type":"code","source":"def printing_random_images(input_dir,n_images=4):\n    # selecting items\n    images_selected = random.choices(os.listdir(input_dir),k=n_images)\n    # instantiating the image template\n    figure = plt.figure(figsize = (22,5))\n    # creating the plot image\n    for i, file_ in enumerate(images_selected):\n        plt.subplot(1, n_images, i+1)\n        #dataset = pydicom.dcmread(os.path.join(input_dir,file_))\n        dataset = dicomsdl.open(os.path.join(input_dir,file_))\n        try:\n            #plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n            plt.imshow(dataset.pixelData(storedvalue=True), cmap=plt.cm.bone)\n            plt.axis('off')\n        except:\n            continue\n\n# printing training images\ntrain_dir_nocancer = r\"/kaggle/working/training/0\"\ntrain_dir_cancer = r\"/kaggle/working/training/1\"\n\nprinting_random_images(input_dir=train_dir_nocancer)\nprinting_random_images(input_dir=train_dir_cancer)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:09.994388Z","iopub.execute_input":"2023-01-03T22:25:09.994890Z","iopub.status.idle":"2023-01-03T22:25:25.155553Z","shell.execute_reply.started":"2023-01-03T22:25:09.994844Z","shell.execute_reply":"2023-01-03T22:25:25.154001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both groups (cancer/no cancer) seems to contain images with white and black backgrounds. The orientation of both groups of images is similar. There is some text in the images (R-MO L-MO) which might be benefitial removing it.\n\n### Turning images into png format\n\nDICOM images are highly informative - these images contain information about the patient such as name, gender, doctor's name, etc. I will be turning these 2.1k images into .png format, which is a very typical image format. In addition, I will be saving such additional information into a .csv file\n\nFirst, I will define a function for converting the image","metadata":{}},{"cell_type":"code","source":"def converting_img_2(img_path,png_ext=True):\n    \"\"\"\n    Adapted method for turning DICOM images into PNG/JPG format\n    \"\"\"\n    try:\n        # directory path\n        dir_path = os.path.dirname(img_path)\n        img_name = os.path.basename(img_path)\n        # reading DICOM image\n        img_dcm = dicomsdl.open(img_path)\n        # to PIL image\n        img_pil = img_dcm.toPilImage()\n        # saving as png or jpg\n        if png_ext:\n            image_name = img_name.replace('.dcm', '.png')\n        else:\n            image_name = img_name.replace('.dcm', '.jpg')\n        im1 = img_pil.save(os.path.join(dir_path,image_name))\n        return(True,img_path)\n    except Exception as e:\n        print(e)\n        return(False,img_path)\n\ndef converting_img_3(img_path,out_path,png_ext=True):\n    \"\"\"\n    Adapted method for turning DICOM images into PNG/JPG format\n    \"\"\"\n    try:\n        # directory path\n        dir_path = os.path.dirname(img_path)\n        img_name = os.path.basename(img_path)\n        # reading DICOM image\n        img_dcm = dicomsdl.open(img_path)\n        # to PIL image\n        img_pil = img_dcm.toPilImage()\n        # saving as png or jpg\n        if png_ext:\n            image_name = img_name.replace('.dcm', '.png')\n        else:\n            image_name = img_name.replace('.dcm', '.jpg')\n        im1 = img_pil.save(os.path.join(out_path,image_name))\n        return(True,img_path)\n    except Exception as e:\n        print(e)\n        return(False,img_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:25.157053Z","iopub.execute_input":"2023-01-03T22:25:25.157678Z","iopub.status.idle":"2023-01-03T22:25:25.168090Z","shell.execute_reply.started":"2023-01-03T22:25:25.157646Z","shell.execute_reply":"2023-01-03T22:25:25.166960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = r\"/kaggle/working/test/2514_464708482.dcm\"\n\ndef dcm_to_png(img_path,out_path,file_ext=\".png\"):\n    # reading image\n    img_dcm = dicomsdl.open(img_path)\n    # to PIL image\n    img_pil = img_dcm.toPilImage()\n    # saving\n    im1 = img_pil.save(os.path.join(out_path,\"test_transformed\"+file_ext))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:25.169204Z","iopub.execute_input":"2023-01-03T22:25:25.169946Z","iopub.status.idle":"2023-01-03T22:25:25.186580Z","shell.execute_reply.started":"2023-01-03T22:25:25.169919Z","shell.execute_reply":"2023-01-03T22:25:25.185318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Converting all images into .png\")\n# Converting all .dcm images into png\nremove_dcm = []\nfor item in os.listdir(r\"/kaggle/working/training/0\"):\n    if item.endswith(\".dcm\"):\n        response = converting_img_2(img_path=os.path.join(r\"/kaggle/working/training/0\",item),png_ext=True)\n        if not response[0]:\n            print(\"Error while processing image: \"+str(response[1]))\n        else:\n            remove_dcm.append(os.path.join(r\"/kaggle/working/training/0\",item))\nfor item in remove_dcm:\n    os.remove(item)\n\nremove_dcm = []\nfor item in os.listdir(r\"/kaggle/working/training/1\"):\n    if item.endswith(\".dcm\"):\n        response = converting_img_2(img_path=os.path.join(r\"/kaggle/working/training/1\",item),png_ext=True)\n        if not response[0]:\n            print(\"Error while processing image: \"+str(response[1]))\n        else:\n            remove_dcm.append(os.path.join(r\"/kaggle/working/training/1\",item))\nfor item in remove_dcm:\n    os.remove(item)\n\nremove_dcm = []\nfor item in os.listdir(r\"/kaggle/working/val/0\"):\n    if item.endswith(\".dcm\"):\n        response = converting_img_2(img_path=os.path.join(r\"/kaggle/working/val/0\",item),png_ext=True)\n        if not response[0]:\n            print(\"Error while processing image: \"+str(response[1]))\n        else:\n            remove_dcm.append(os.path.join(r\"/kaggle/working/val/0\",item))\nfor item in remove_dcm:\n    os.remove(item)\n\nremove_dcm = []\nfor item in os.listdir(r\"/kaggle/working/val/1\"):\n    if item.endswith(\".dcm\"):\n        response = converting_img_2(img_path=os.path.join(r\"/kaggle/working/val/1\",item),png_ext=True)\n        if not response[0]:\n            print(\"Error while processing image: \"+str(response[1]))\n        else:\n            remove_dcm.append(os.path.join(r\"/kaggle/working/val/1\",item))\nfor item in remove_dcm:\n    os.remove(item)\n\nprint(\"All images have been converted! \")","metadata":{"execution":{"iopub.status.busy":"2023-01-03T22:25:25.188648Z","iopub.execute_input":"2023-01-03T22:25:25.189108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and validating\n\nAll the data is ready for training - it has been preprocessed and grouped in training and validation. This task is a binary classification task. Importantly, there are only ca. 2k images for training, which is a relatively small number of images. For this initial trial, I will use a pretrained model and fine-tune it on our task. \n\n### Further data-preprocessing and augmentation\n\nIn order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n\nAdding the augmentation and pre-processing:","metadata":{}},{"cell_type":"code","source":"print(\"Defining the image data generator\")\n# defining the training and validation directories\ntrain_dir = r\"/kaggle/working/training\"\nvalidation_dir = r\"/kaggle/working/val\"\n# defining the batch size\nbatch_size = 16\n# defining the image target size\ntarget_size=(224, 224)\n\n# adding augmentation and preprocessing (floating point number)\ntrain_datagen = ImageDataGenerator()\n\n# for the validation set, just the preprocessing\ntest_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,target_size=target_size,batch_size=batch_size,class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,target_size=target_size,batch_size=batch_size,class_mode='binary')\n\nprint(train_generator.class_indices)\nprint(validation_generator.class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen above, there are only 400 images for validation. Hence, this strategy can have a high variance - depending on the validation slot selected, the performance of the model is different. This is something to improve in the next training.","metadata":{}},{"cell_type":"markdown","source":"## Defining the model\n\nI will be using Resnet50 for this problem. As we do not have much data, I will fine tune the last few layers from a pre-trained Resnet 50. Let's see how much performance we can obtain using this simple approach.","metadata":{}},{"cell_type":"code","source":"print(\"Defining the convolutional base of the ML\")\n# Convoluted Base MODEL\n\nconv_base = tf.keras.applications.resnet50.ResNet50(weights=r'/kaggle/input/tf-keras-pretrained-model-weights/No Top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\ninclude_top=False,\ninput_shape=(224, 224, 3))\n\nprint(conv_base.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Defining the ML model architecture\")\n# MODEL 1\n\ninput_layer = tf.keras.layers.Input([224, 224, 3], dtype = tf.uint8)\nx = tf.keras.layers.RandomFlip(mode='horizontal')(input_layer)\nx = tf.keras.layers.RandomContrast(factor=[0.95,1.05])(x)\nx = tf.cast(x, tf.float32)\nx = tf.keras.applications.resnet50.preprocess_input(x)\nx = conv_base(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = tf.keras.Model(inputs=[input_layer], outputs=[x])\n\n#model = tf.keras.Sequential()\n#model.add(tf.keras.layers.RandomFlip(mode='horizontal'))\n#model.add(tf.keras.layers.RandomContrast(factor=[0.95,1.05]))\n#model.add(tf.keras.layers.Rescaling(1./1))\n#model.add(tf.keras.applications.resnet50.preprocess_input())\n#model.add(conv_base)\n#model.add(tf.keras.layers.GlobalAveragePooling2D())\n#model.add(tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=tf.keras.regularizers.l1(0.01)))\n\n# MODEL 2\n\nmodel2 = tf.keras.Sequential()\nmodel2.add(conv_base)\nmodel2.add(tf.keras.layers.Flatten())\nmodel2.add(tf.keras.layers.Dropout(0.5))\nmodel2.add(tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\nmodel2.add(tf.keras.layers.Dropout(0.5))\nmodel2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nprint(model.summary())\n\nprint(model2.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freezing the convolutional base\nfor layer in conv_base.layers[:]:\n    layer.trainable = False\n\nfor i, layer in enumerate(conv_base.layers):\n    print(i, layer.name, layer.trainable)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Defining callbacks\")\n# Adding callbacks\n# early stopping\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=10,\n    mode=\"max\",\n)\n# checkpoint saving\nif os.path.isdir(r\"/kaggle/working/training_model/model/conv_base\"):\n    shutil.rmtree(r\"/kaggle/working/training_model/model/conv_base\")\n    os.makedirs(r\"/kaggle/working/training_model/model/conv_base\")\nelse:\n    os.makedirs(r\"/kaggle/working/training_model/model/conv_base\")\n# checkpint callback for saving model\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=r\"/kaggle/working/training_model/model/conv_base\",\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True) # only saving the best version of the model\n\n# Defining callbacks\nmy_callbacks = [early_stopping_callback,model_checkpoint_callback]\n\n# Compile frozen conv_base + my top layer\n# I will start training the second model first\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n              loss='binary_crossentropy',\n              metrics=['accuracy',tf.keras.metrics.BinaryAccuracy()])\n\nprint(\"model compiled\")\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note\nIt’s necessary to freeze the convolution base of the conv base in order to be able to train a randomly initialized classifier on top using a high learning rate. Otherwise, the error signal propagating through the network during training will be too large, and the representations previously learned by the layers being fine-tuned will be destroyed.\n\n#### Strategy\n1) Train just the classifier with predefined lr - conv_base frozen \n\n2) Unfreeze last model conv block, recompile and train all with LOW lr=1e-5","metadata":{}},{"cell_type":"code","source":"print(\"Training!\")\n#Short training ONLY my top layers \n#... so the conv_base weights will not be destroyed by the random intialization of the new weights\n\nhistory = model.fit(train_generator,\n                              epochs=100,\n                              validation_data = validation_generator,\n                              callbacks=my_callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Done! I have got to the end of the training the convolutional base!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine Tuning the model\n\nNow, I am going to fine tune a few more layers from the Resnet50 so I can get some more performance","metadata":{}},{"cell_type":"code","source":"# loading model\nmodel.load_weights(r\"/kaggle/working/training_model/model/conv_base\")\n\n# Make last block of the conv_base trainable:\n\nfor layer in conv_base.layers[:165]:\n    layer.trainable = False\nfor layer in conv_base.layers[165:]:\n    layer.trainable = True\n\nprint('Last block of the conv_base is now trainable')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(conv_base.layers):\n    print(i, layer.name, layer.trainable)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Defining callbacks\")\n# Adding callbacks\n# early stopping\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=15,\n    mode=\"max\",\n)\n# checkpoint saving\nif os.path.isdir(r\"/kaggle/working/training_model/model/fine_tuned\"):\n    shutil.rmtree(r\"/kaggle/working/training_model/model/fine_tuned\")\n    os.makedirs(r\"/kaggle/working/training_model/model/fine_tuned\")\nelse:\n    os.makedirs(r\"/kaggle/working/training_model/model/fine_tuned\")\n# checkpint callback for saving model\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=r\"/kaggle/working/training_model/model/fine_tuned\",\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True) # only saving the best version of the model\n\n# Defining callbacks\nmy_callbacks = [early_stopping_callback,model_checkpoint_callback]\n\n# Compile frozen conv_base + my top layer\n# I will start training the second model first\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n              loss='binary_crossentropy',\n              metrics=['accuracy',tf.keras.metrics.BinaryAccuracy()])\n\nprint(\"model compiled\")\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training!\")\n#Short training ONLY my top layers \n#... so the conv_base weights will not be destroyed by the random intialization of the new weights\n\nhistory = model.fit(train_generator,\n                              epochs=200,\n                              validation_data = validation_generator,\n                              callbacks=my_callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Validation\n\nI will reconstruct the model and deploy it on the validation set, so I can obtain the metrics of the best version","metadata":{}},{"cell_type":"code","source":"# Loading best weights\nmodel.load_weights(r\"/kaggle/working/training_model/model/fine_tuned\")\n\n# Validating\nresults = model.evaluate(validation_generator)\nprint(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAVE model\nmodel.save('RSNA_screening_Resnet50.h5')\nprint(\"RSNA_screening_Resnet50.h5 was saved\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n\nFinally, I will prepare the .csv file for submission.","metadata":{}},{"cell_type":"code","source":"print(\"Preparing for submission\")\n# loading the model\nnew_model = tf.keras.models.load_model(r'RSNA_screening_Resnet50.h5')\n# preparing and saving images from the test directory\nos.makedirs(os.path.join(r\"/kaggle/working/\",\"output\"),exist_ok=True)\nout_temp = os.path.join(r\"/kaggle/working/\",\"output\")\n\nfor root, dirs, files in os.walk(r\"/kaggle/input/rsna-breast-cancer-detection/test_images\", topdown=False):\n    for name in files:\n        if name.endswith(\".dcm\"):\n            response = converting_img_3(img_path=os.path.join(root,name),out_path=out_temp,png_ext=True)\n            if not response[0]:\n                print(\"Error while processing image: \"+str(response[1]))\n            else:\n                print(\"Success!\")\n\n# defining the batch size\nbatch_size = 1\n# defining the image target size\ntarget_size=(224, 224)\n\n# for the validation set, just the preprocessing\ntest_datagen = ImageDataGenerator()\n\ntest_generator = test_datagen.flow_from_directory(\n    out_temp,target_size=target_size,batch_size=batch_size,class_mode='binary')\n\nprint(test_generator.class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding column cancer\ntest_df['cancer']=np.random.rand(test_df.shape[0])\n\nfor item in os.listdir(out_temp):\n    # non duplicate variable\n    non_duplicate = False\n    # defining image path\n    img_path = os.path.join(out_temp,item)\n    # extracting corresponding info from the dataframe\n    for index,row in test_df.iterrows():\n        if str(row[\"image_id\"]) == item[:-4]:\n            # obtaining cancer probability\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n            # creating an array\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            # creating the batch axis\n            img_array = tf.expand_dims(img_array, 0)\n            # predicting on image\n            predictions = new_model.predict(img_array)\n            score = float(predictions[0])\n            \n            # adding the result\n            row[\"cancer\"] = score\n            break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing submission dataframe\nsubmission_df= test_df[['prediction_id','cancer']].groupby('prediction_id').max().reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submitting\nsubmission_df.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}